
@article{grossVariabilitySignificanceClass2013,
	title = {The variability and significance of class characteristics in footwear impressions},
	volume = {63},
	number = {3},
	journal = {Journal of Forensic Identification},
	author = {Gross, Susan and Jeppesen, Dane and Neumann, Cedric},
	year = {2013},
	note = {00001},
	pages = {332},
	file = {Gross et al_2013_The variability and significance of class characteristics in footwear.pdf:/home/srvander/Zotero/storage/EC9IV5R5/Gross et al_2013_The variability and significance of class characteristics in footwear.pdf:application/pdf}
}

@book{bodziakfootwear2000,
	address = {Boca Raton, Florida},
	title = {Footwear {Impression} {Evidence}: {Detection}, {Recovery}, and {Examination}},
	isbn = {0-8493-1045-8},
	publisher = {CRC Press},
	author = {Bodziak, William J.},
	year = {2000}
}


@inproceedings{alexanderAutomaticClassificationRecognition1999,
	title = {Automatic classification and recognition of shoeprints},
	volume = {2},
	doi = {10.1049/cp:19990401},
	abstract = {The most common clues left at a crime scene when a crime is committed are shoeprint impressions. These impressions are useful in the detection of criminals and the linking of crime scenes. We are currently working on a fully automatic system utilising novel fractal pattern matching techniques which allow the investigating officer(s) to match collected impressions against a database of known shoeprint patterns. There is currently no other shoeprint impression database available that offers this facility.},
	booktitle = {Image {Processing} {And} {Its} {Applications}, 1999. {Seventh} {International} {Conference} on ({Conf}. {Publ}. {No}. 465)},
	author = {Alexander, A and Bouridane, A and Crookes, D},
	month = jul,
	year = {1999},
	keywords = {image matching, recognition, automatic classification, collected impressions, crime scene, criminals, fractal pattern matching techniques, fully automatic system, shoeprints},
	pages = {638--641 vol.2}
}


@inproceedings{pavlouAutomaticExtractionClassification2006,
	title = {Automatic extraction and classification of footwear patterns},
	booktitle = {International {Conference} on {Intelligent} {Data} {Engineering} and {Automated} {Learning}},
	publisher = {Springer},
	author = {Pavlou, Maria and Allinson, Nigel M},
	year = {2006},
	pages = {721--728}
}


@inproceedings{guehamAutomaticRecognitionShoeprints2008,
	title = {Automatic {Recognition} of {Shoeprints} using {Fourier}-{Mellin} {Transform}},
	doi = {10.1109/AHS.2008.48},
	abstract = {This paper proposes a technique for automatically recognising shoeprint images for use in forensic science. The method uses the Fourier-Mellin transform to produce translation, rotation and scale invariant features. A two dimensional correlation is employed as the similarity metric for the classification process. Experiments were conducted on a database of 500 different shoeprint images representing a part of available shoes on the market. In order to test the robustness of the method, test images including different perturbations such as noise addition and cropping (partial shoeprints) were generated. Experimental results show that the proposed method is very practical providing attractive performance when processing distorted shoeprint images.},
	booktitle = {2008 {NASA}/{ESA} {Conference} on {Adaptive} {Hardware} and {Systems}},
	author = {Gueham, M. and Bouridane, A. and Crookes, D. and Nibouche, O.},
	month = jun,
	year = {2008},
	pages = {487--491}
}


@incollection{krizhevskyImageNetClassificationDeep2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	urldate = {2019-03-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105}
}


@inproceedings{zhangAdaptingConvolutionalNeural2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adapting {Convolutional} {Neural} {Networks} on the {Shoeprint} {Retrieval} for {Forensic} {Use}},
	isbn = {978-3-319-69923-3},
	abstract = {Shoeprint is an important evidence for crime investigation. Many automatic shoeprint retrieval methods have been proposed in order to efficiently provide useful information for the identification of the criminals. In the mean time, the convolutional neural network shows great capacity in image classification problem but its application in shoeprint retrieval is not yet investigated. This paper presents an application of VGG16 network as feature extractor in shoeprint retrieval and a data augmentation method to fine-tune the neural network with a very small database. Our method shows a much better performance compared with state-of-the-art methods on a same database with crime-scene-like shoeprints.},
	language = {en},
	booktitle = {Biometric {Recognition}},
	publisher = {Springer International Publishing},
	author = {Zhang, Yang and Fu, Huanzhang and Dellandréa, Emmanuel and Chen, Liming},
	editor = {Zhou, Jie and Wang, Yunhong and Sun, Zhenan and Xu, Yong and Shen, Linlin and Feng, Jianjiang and Shan, Shiguang and Qiao, Yu and Guo, Zhenhua and Yu, Shiqi},
	year = {2017},
	note = {00002},
	keywords = {Feature extraction, Convolutional neural network, Deep learning, Fine-tuning, Shoeprint retrieval},
	pages = {520--527},
	file = {Zhang et al_2017_Adapting Convolutional Neural Networks on the Shoeprint Retrieval for Forensic.pdf:/home/susan/Zotero/storage/IYR634DJ/Zhang et al_2017_Adapting Convolutional Neural Networks on the Shoeprint Retrieval for Forensic.pdf:application/pdf}
}

@article{kongCrossDomainForensicShoeprint2017,
	title = {Cross-{Domain} {Forensic} {Shoeprint} {Matching}},
	abstract = {We investigate the problem of automatically determining what type of shoe left an impression found at a crime scene. This recognition problem is made difﬁcult by the variability in types of crime scene evidence (ranging from traces of dust or oil on hard surfaces to impressions made in soil) and the lack of comprehensive databases of shoe outsole tread patterns. We ﬁnd that mid-level features extracted by pre-trained convolutional neural nets are surprisingly effective descriptors for these specialized domains. However, the choice of similarity measure for matching exemplars to a query image is essential to good performance. For matching multi-channel deep features, we propose the use of multi-channel normalized cross-correlation and analyze its effectiveness. Finally, we introduce a discriminatively trained variant and ﬁne-tune our system end-to-end, obtaining state-of-the-art performance.},
	language = {en},
	journal = {British Machine Vision Conference},
	author = {Kong, Bailey and Supancic, James and Ramanan, Deva and Fowlkes, Charless},
	year = {2017},
	pages = {17},
}

@article{kongCrossDomainImageMatching2019,
	title = {Cross-{Domain} {Image} {Matching} with {Deep} {Feature} {Maps}},
	issn = {0920-5691, 1573-1405},
	url = {http://arxiv.org/abs/1804.02367},
	doi = {10.1007/s11263-018-01143-3},
	abstract = {We investigate the problem of automatically determining what type of shoe left an impression found at a crime scene. This recognition problem is made difficult by the variability in types of crime scene evidence (ranging from traces of dust or oil on hard surfaces to impressions made in soil) and the lack of comprehensive databases of shoe outsole tread patterns. We find that mid-level features extracted by pre-trained convolutional neural nets are surprisingly effective descriptors for this specialized domains. However, the choice of similarity measure for matching exemplars to a query image is essential to good performance. For matching multi-channel deep features, we propose the use of multi-channel normalized cross-correlation and analyze its effectiveness. Our proposed metric significantly improves performance in matching crime scene shoeprints to laboratory test impressions. We also show its effectiveness in other cross-domain image retrieval problems: matching facade images to segmentation labels and aerial photos to map images. Finally, we introduce a discriminatively trained variant and fine-tune our system through our proposed metric, obtaining state-of-the-art performance.},
	urldate = {2019-03-14},
	journal = {International Journal of Computer Vision},
	author = {Kong, Bailey and Supancic, James and Ramanan, Deva and Fowlkes, Charless C.},
	month = jan,
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Cross-domain image matching, Normalized cross-correlation, Similarity metric},
}


@article{davisIntelligenceApproachFootwear1981,
	title = {An {Intelligence} {Approach} to {Footwear} {Marks} and {Toolmarks}},
	volume = {21},
	number = {3},
	journal = {Journal of the Forensic Science Society},
	author = {{R. J. Davis}},
	year = {1981},
	pages = {183--193},
}

@article{grossVariabilitySignificanceClass2013,
	title = {The variability and significance of class characteristics in footwear impressions},
	volume = {63},
	number = {3},
	journal = {Journal of Forensic Identification},
	author = {Gross, Susan and Jeppesen, Dane and Neumann, Cedric},
	year = {2013},
	note = {00001},
	pages = {332},
	file = {Gross et al_2013_The variability and significance of class characteristics in footwear.pdf:/home/srvander/Zotero/storage/EC9IV5R5/Gross et al_2013_The variability and significance of class characteristics in footwear.pdf:application/pdf}
}

@book{bodziakfootwear2000,
	address = {Boca Raton, Florida},
	title = {Footwear {Impression} {Evidence}: {Detection}, {Recovery}, and {Examination}},
	isbn = {0-8493-1045-8},
	publisher = {CRC Press},
	author = {Bodziak, William J.},
	year = {2000}
}

@inproceedings{alexanderAutomaticClassificationRecognition1999,
	title = {Automatic classification and recognition of shoeprints},
	volume = {2},
	doi = {10.1049/cp:19990401},
	abstract = {The most common clues left at a crime scene when a crime is committed are shoeprint impressions. These impressions are useful in the detection of criminals and the linking of crime scenes. We are currently working on a fully automatic system utilising novel fractal pattern matching techniques which allow the investigating officer(s) to match collected impressions against a database of known shoeprint patterns. There is currently no other shoeprint impression database available that offers this facility.},
	booktitle = {Image {Processing} {And} {Its} {Applications}, 1999. {Seventh} {International} {Conference} on ({Conf}. {Publ}. {No}. 465)},
	author = {Alexander, A and Bouridane, A and Crookes, D},
	month = jul,
	year = {1999},
	keywords = {image matching, recognition, automatic classification, collected impressions, crime scene, criminals, fractal pattern matching techniques, fully automatic system, shoeprints},
	pages = {638--641 vol.2}
}


@inproceedings{pavlouAutomaticExtractionClassification2006,
	title = {Automatic extraction and classification of footwear patterns},
	booktitle = {International {Conference} on {Intelligent} {Data} {Engineering} and {Automated} {Learning}},
	publisher = {Springer},
	author = {Pavlou, Maria and Allinson, Nigel M},
	year = {2006},
	pages = {721--728}
}

@article{rathinavelFullShoePrint2011,
	title = {Full {Shoe} {Print} {Recognition} based on {Pass} {Band} {DCT} and {Partial} {Shoe} {Print} {Identification} using {Overlapped} {Block} {Method} for {Degraded} {Images}},
	volume = {26},
	issn = {09758887},
	url = {http://www.ijcaonline.org/volume26/number8/pxc3874301.pdf},
	doi = {10.5120/3126-4301},
	abstract = {In this paper, a novel approach is made to discard the degradations in full shoe prints and partial shoe prints, in processing those images for recognition. A pass band DCT coefficient has been used to extract feature vectors. A more robust approach has been dealt with to find the matching between the partial shoe prints and the images in the data base. This method makes the shoe print recognition process more robust against degradations like noises, orientations and blurred images which are common in shoe print images and also helps in saving the processing time and memory consumption.},
	language = {en},
	number = {8},
	urldate = {2019-03-05},
	journal = {International Journal of Computer Applications},
	author = {Rathinavel, S. and Arumugam, S.},
	month = jul,
	year = {2011},
	pages = {16--21}
}

@inproceedings{cervelliTranslationalRotationalInvariant,
	address = {Aalborg, Denmark},
	title = {A {Translational} {And} {Rotational} {Invariant} {Descriptor} {For} {Automatic} {Footwear} {Retrieval} {Of} {Real} {Cases} {Shoe} {Marks}},
	abstract = {Shoe marks found on the crime scene are invaluable for the identiﬁcation of the culprit when no other piece of evidence is available. Thus semi-automatic and automatic systems have been recently proposed to ﬁnd the make and model of the footwear that left the shoe marks. The systems proposed up to now have two main drawbacks, as they (i) are generally not based on rotation and translation invariant descriptions, and (ii) are tested on synthetic shoe marks, i.e. on shoeprints with added synthetic noise. Here we show the results of a translation and rotation invariant description based on the Fourier transform properties: the test is made on both synthetic and real shoe marks and a comparison with algorithms proposed by others is presented.},
	language = {en},
	publisher = {EURASIP},
	author = {Cervelli, Federico and Dardi, Francesca and Carrato, Sergio},
	pages = {1665--1669}
}

@inproceedings{guehamAutomaticRecognitionShoeprints2008,
	title = {Automatic {Recognition} of {Shoeprints} using {Fourier}-{Mellin} {Transform}},
	doi = {10.1109/AHS.2008.48},
	abstract = {This paper proposes a technique for automatically recognising shoeprint images for use in forensic science. The method uses the Fourier-Mellin transform to produce translation, rotation and scale invariant features. A two dimensional correlation is employed as the similarity metric for the classification process. Experiments were conducted on a database of 500 different shoeprint images representing a part of available shoes on the market. In order to test the robustness of the method, test images including different perturbations such as noise addition and cropping (partial shoeprints) were generated. Experimental results show that the proposed method is very practical providing attractive performance when processing distorted shoeprint images.},
	booktitle = {2008 {NASA}/{ESA} {Conference} on {Adaptive} {Hardware} and {Systems}},
	author = {Gueham, M. and Bouridane, A. and Crookes, D. and Nibouche, O.},
	month = jun,
	year = {2008},
	pages = {487--491}
}


@incollection{krizhevskyImageNetClassificationDeep2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	urldate = {2019-03-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105}
}

@inproceedings{zhangAdaptingConvolutionalNeural2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adapting {Convolutional} {Neural} {Networks} on the {Shoeprint} {Retrieval} for {Forensic} {Use}},
	isbn = {978-3-319-69923-3},
	abstract = {Shoeprint is an important evidence for crime investigation. Many automatic shoeprint retrieval methods have been proposed in order to efficiently provide useful information for the identification of the criminals. In the mean time, the convolutional neural network shows great capacity in image classification problem but its application in shoeprint retrieval is not yet investigated. This paper presents an application of VGG16 network as feature extractor in shoeprint retrieval and a data augmentation method to fine-tune the neural network with a very small database. Our method shows a much better performance compared with state-of-the-art methods on a same database with crime-scene-like shoeprints.},
	language = {en},
	booktitle = {Biometric {Recognition}},
	publisher = {Springer International Publishing},
	author = {Zhang, Yang and Fu, Huanzhang and Dellandréa, Emmanuel and Chen, Liming},
	editor = {Zhou, Jie and Wang, Yunhong and Sun, Zhenan and Xu, Yong and Shen, Linlin and Feng, Jianjiang and Shan, Shiguang and Qiao, Yu and Guo, Zhenhua and Yu, Shiqi},
	year = {2017},
	keywords = {Feature extraction, Convolutional neural network, Deep learning, Fine-tuning, Shoeprint retrieval},
	pages = {520--527}
}

@article{kongCrossDomainImageMatching2019a,
	title = {Cross-{Domain} {Image} {Matching} with {Deep} {Feature} {Maps}},
	issn = {0920-5691, 1573-1405},
	url = {http://arxiv.org/abs/1804.02367},
	doi = {10.1007/s11263-018-01143-3},
	abstract = {We investigate the problem of automatically determining what type of shoe left an impression found at a crime scene. This recognition problem is made difficult by the variability in types of crime scene evidence (ranging from traces of dust or oil on hard surfaces to impressions made in soil) and the lack of comprehensive databases of shoe outsole tread patterns. We find that mid-level features extracted by pre-trained convolutional neural nets are surprisingly effective descriptors for this specialized domains. However, the choice of similarity measure for matching exemplars to a query image is essential to good performance. For matching multi-channel deep features, we propose the use of multi-channel normalized cross-correlation and analyze its effectiveness. Our proposed metric significantly improves performance in matching crime scene shoeprints to laboratory test impressions. We also show its effectiveness in other cross-domain image retrieval problems: matching facade images to segmentation labels and aerial photos to map images. Finally, we introduce a discriminatively trained variant and fine-tune our system through our proposed metric, obtaining state-of-the-art performance.},
	urldate = {2019-03-14},
	journal = {International Journal of Computer Vision},
	author = {Kong, Bailey and Supancic, James and Ramanan, Deva and Fowlkes, Charless C.},
	month = jan,
	year = {2019}
}

@article{kongCrossDomainForensicShoeprint2017,
	title = {Cross-{Domain} {Forensic} {Shoeprint} {Matching}},
	abstract = {We investigate the problem of automatically determining what type of shoe left an impression found at a crime scene. This recognition problem is made difﬁcult by the variability in types of crime scene evidence (ranging from traces of dust or oil on hard surfaces to impressions made in soil) and the lack of comprehensive databases of shoe outsole tread patterns. We ﬁnd that mid-level features extracted by pre-trained convolutional neural nets are surprisingly effective descriptors for these specialized domains. However, the choice of similarity measure for matching exemplars to a query image is essential to good performance. For matching multi-channel deep features, we propose the use of multi-channel normalized cross-correlation and analyze its effectiveness. Finally, we introduce a discriminatively trained variant and ﬁne-tune our system end-to-end, obtaining state-of-the-art performance.},
	language = {en},
	journal = {British Machine Vision Conference},
	author = {Kong, Bailey and Supancic, James and Ramanan, Deva and Fowlkes, Charless},
	year = {2017},
	pages = {17},
}

@article{chazalAutomatedProcessingShoeprint2005,
	title = {Automated processing of shoeprint images based on the {Fourier} transform for use in forensic science},
	volume = {27},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2005.48},
	abstract = {The development of a system for automatically sorting a database of shoeprint images based on the outsole pattern in response to a reference shoeprint image is presented. The database images are sorted so that those from the same pattern group as the reference shoeprint are likely to be at the start of the list. A database of 476 complete shoeprint images belonging to 140 pattern groups was established with each group containing two or more examples. A panel of human observers performed the grouping of the images into pattern categories. Tests of the system using the database showed that the first-ranked database image belongs to the same pattern category as the reference image 65 percent of the time and that a correct match appears within the first 5 percent of the sorted images 87 percent of the time. The system has translational and rotational invariance so that the spatial positioning of the reference shoeprint images does not have to correspond with the spatial positioning of the shoeprint images of the database. The performance of the system for matching partial-prints was also determined.},
	number = {3},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Chazal, P. de and Flynn, J. and Reilly, R. B.},
	month = mar,
	year = {2005},
	pages = {341--350}
}


@article{luostarinenMeasuringAccuracyAutomatic2014a,
	title = {Measuring the {Accuracy} of {Automatic} {Shoeprint} {Recognition} {Methods}},
	volume = {59},
	issn = {00221198},
	url = {http://doi.wiley.com/10.1111/1556-4029.12474},
	doi = {10.1111/1556-4029.12474},
	abstract = {Shoeprints are an important source of information for criminal investigation. Therefore, an increasing number of automatic shoeprint recognition methods have been proposed for detecting the corresponding shoe models. However, comprehensive comparisons among the methods have not previously been made. In this study, an extensive set of methods proposed in the literature was implemented, and their performance was studied in varying conditions. Three datasets of different quality shoeprints were used, and the methods were evaluated also with partial and rotated prints. The results show clear differences between the algorithms: while the best performing method, based on local image descriptors and RANSAC, provides rather good results with most of the experiments, some methods are almost completely unrobust against any unidealities in the images. Finally, the results demonstrate that there is still a need for extensive research to improve the accuracy of automatic recognition of crime scene prints.},
	language = {en},
	number = {6},
	urldate = {2019-04-12},
	journal = {Journal of Forensic Sciences},
	author = {Luostarinen, Tapio and Lehmussola, Antti},
	month = nov,
	year = {2014},
	pages = {1627--1634},
}


@article{davisIntelligenceApproachFootwear1981,
	title = {An {Intelligence} {Approach} to {Footwear} {Marks} and {Toolmarks}},
	volume = {21},
	number = {3},
	journal = {Journal of the Forensic Science Society},
	author = {{R. J. Davis}},
	year = {1981},
	pages = {183--193},
}
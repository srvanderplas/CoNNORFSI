\documentclass[review]{elsarticle}

\usepackage{lineno,hyperref}
\modulolinenumbers[5]

\journal{Forensic Science International}

%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

<<setup, include = F>>=
knitr::opts_chunk$set(echo = F, dev = "pdf", dpi = 1000)
@

\begin{document}

\begin{frontmatter}

\title{A Convolutional Neural Network for Outsole Recognition\tnoteref{t1}}
\tnotetext[t1]{This document is the results of the research
project funded ....}

%% Group authors per affiliation:
% \author{Miranda Tilton and Susan Vanderplas\fnref{csafe}}
% \address{Iowa State University Statistics Department}
% \fntext[csafe]{195 Durham Center, 613 Morill Rd., Ames, IA 50011}

% or include affiliations in footnotes:
\author[1]{Miranda Tilton\fnref{isu}}
\ead{tiltonm@iastate.edu}

\author[1]{Susan Vanderplas\corref{cor1}\fnref{isu}}
\cortext[cor1]{Corresponding author}
\ead{srvander@iastate.edu}

\address[1]{195 Durham Center, 613 Morill Rd, Ames, IA 50010}
\fntext[isu]{Center for Statistical Applications in Forensic Evidence, Iowa State University}

\begin{abstract}
This template helps you to create a properly formatted \LaTeX\ manuscript.
\end{abstract}

\begin{keyword}
footwear,class characteristics,computer vision, neural networks
\end{keyword}

\end{frontmatter}

\linenumbers

\section{Introduction}
Most forensic examinations of footwear pattern evidence are limited to class characteristic based matches; that is, matches based on the positioning of geometric features within the tread pattern. Some of these features may include brand logos and size markings, while others are more generic geometric shapes, such as circles, triangles, stars, and chevrons. Class characteristic matches can be used for elimination, but are not sufficient for identification, as the characteristics are shared by all shoes with the same size, make, and model \citep{grossVariabilitySignificanceClass2013,bodziakfootwear2000}. Several attempts have been made to automatically identify features in both prints and shoe tread images, with low-level image analysis methods including fractal decomposition \citep{alexanderAutomaticClassificationRecognition1999}, scale-invariant feature recognition \citep{pavlouAutomaticExtractionClassification2006}, Fourier-Mellin transformation \citep{guehamAutomaticRecognitionShoeprints2008}, and other classical image analysis methods. Some of these low-level methods perform relatively well in good conditions \citep{luostarinenMeasuringAccuracyAutomatic2014a} but have degraded performance under conditions which are suboptimal, including those commonly found at crimescenes.

In the wider field of computer vision, attention has turned to more robust methods for image recognition, such as convolutional neural networks (CNNs), which are capable of achieving near-human accuracy under even degraded image conditions\citep{krizhevskyImageNetClassificationDeep2012}. These networks are designed to mimic the process of human vision, and typically involve application of sets of filters, some of which mimic the filters used in the low-level techniques used by early automatic classification attempts. CNNs have been applied in footwear forensics, making use of more general neural networks optimized to detect objects found in natural scenes, such as trees, animals, buildings, and cars; the pre-trained network's features are then used to compare shoes or prints to determine how well they match \citep{kongCrossDomainImageMatching2019a,kongCrossDomainForensicShoeprint2017,zhangAdaptingConvolutionalNeural2017}. Neural network methods appear to be more successful than traditional image analysis techniques, but the features used for matching are not generally informative for humans, who typically classify shoes by patterns and spatial relationships \citep{davisIntelligenceApproachFootwear1981,grossVariabilitySignificanceClass2013}.

In this paper, we discuss an alternate approach that uses an additional model layer to transfer the feature vector output into a vector of probabilities representing the detection of geometric elements in shoe tread images. Working within the feature space used by forensic examiners allows us to augment human-identified features with model output, assessing similarity of different shoe images on a feature set that is explicitly relevant to the domain.

\section{Materials and Methods}
\paragraph{Transfer Learning}
New content: Convolutional neural networks consist of a model base, comprised of feature detectors which are used to map the characteristics of an image, and a classifier (or model head) that uses weights to meaningfully connect image features to classification labels. A relatively simple CNN may contain more than 20 million parameters that must be trained on human-labelled data. Training a CNN from scratch for a new image classification task requires millions of training images and a substantial amount of computational power. (XXX Features are relatively flexible, and new objects are likely some combination of those features.) Thus, although a model base may be trained for one task, it is often easily applied to a new task.

Stolen from CC: Transfer learning is the process of using layers from a CNN (or other classification model) trained on a general image recognition task when fitting a model intended for a more specific purpose. The layers which are deemed to identify broadly generalizable patterns are used with their pre-trained weights; new layers are added to customize the model to the specific task at hand, and typically, only these new weights are updated when the model is fit. In many cases, the entire model base is used, and fitted with a new model head; the modularity of CNNs makes this process relatively simple, and allows researchers to leverage pre-trained networks when working with diffierent sets of image data. Transfer learning allows CNNs to be applied to smaller datasets of several thousand images and also reduces the amount of computational time required to fit the model. Transfer learning leverages the modularity of neural networks|the pretrained base of the model can be separated from the full model and a new model head can be trained to connect that base to the output classes.

\paragraph{VGG16}
Developed by Oxford's Visual Graphics Group, VGG16 is a CNN with 16 ``\functional" (i.e., convolutional and densely connected) layers and 5 ``\structural" max pooling layers. In contrast to other popular networks, like ResNet, VGG has a relatively simple structure that provides easier training and interpretability with very little sacrificed accuracy. The simplicity of this structure provides the ability to peer into the inner workings of the network for diagnostic purposes, providing a distinct advantage over more complicated network structures with slightly higher accuracy ratings.

Also mention ImageNet somewhere...

\paragraph{LabelMe Shoe Annotations}
Nine geometric class characteristics were chosen: Circle, ..., and Text. Thousands of outsole images were scraped online shoe retail sites. These images were then uploaded for use in a tool called LabelMe (Russell et al., 2008), a labeling/annotating interface which allows users to easily select and label regions of an image. To date, 4371 shoes have been labeled, yielding 27135 multi-label images.



\section{Results}
\paragraph{Overall Accuracy} % Model-wise and class-by-class, w/ confusion matrix

\paragraph{Model Diagnostics}

\section{Conclusions}

\section{Future Work}


\section*{References}

\bibliography{mybibfile}

\end{document}